{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "Before we start, let's make sure everything is working as it should.\n",
    "\n",
    "#### 1. Python Dependencies\n",
    "\n",
    "We need to install 2 libraries (`google-cloud-storage` and `google-cloud-speech`). If you're running this tutorial on [notebooks.ai](https://notebooks.ai) you're all set. In other case, you'll have to manually install them (check `requirements.txt`).\n",
    "\n",
    "To verify everything is working, let's run the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from google.cloud.speech_v1p1beta1 import enums\n",
    "from google.cloud.speech_v1p1beta1 import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Credentials\n",
    "\n",
    "If you follow the tutorial from the other notebook (`Tutorial.ipynb`), you saw you have to replace Google credentials in the file `google-demo-speech-to-text.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = json.load(open('google-demo-speech-to-text.json'))\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_info(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify they're valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials.expired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Audio uploaded to Cloud Storage\n",
    "\n",
    "As we mentioned in the tutorial, the audio files to be transcribed should be uploaded to _Google Cloud Storage_. Replace the following variables with the correct values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE IT TO YOUR OWN BUCKET NAME\n",
    "BUCKET_NAME = 'rmotr-speech-to-text-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE IT TO THE FILE NAME OF YOUR AUDIO\n",
    "AUDIO_FILE_NAME = 'jacob-keynote.flac'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll connect to the service using the library client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=credentials.project_id, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage_client.get_bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(AUDIO_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert blob.exists(), \"Warning! Audio file not accesible\"\n",
    "blob.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test if the audio is correct. We'll download it in memory and play it.\n",
    "\n",
    "**WARNING:** Only do this if your audio is small (<2MB)! Large files will take time and memory, just skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_content = blob.download_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're all set! Time to do the transcription\n",
    "\n",
    "### Transcribing audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll initialize a `SpeechClient` from the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = speech.SpeechClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to construct the URI based on bucket and file name to point the Speech to Text service to the audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS\n",
    "audio_uri = f'gs://{BUCKET_NAME}/{AUDIO_FILE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Audio uri: {audio_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘† is this correct? It should if it worked in the previous setup step. Just make sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to create the transcription config, this is the place where you can customize the process. All the parameters accepted are available at the docs (**recommended**): https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig\n",
    "\n",
    "The most important parameters I'm specifying here are:\n",
    "\n",
    "* `encoding`, use FLAC. Full reference: https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig#AudioEncoding\n",
    "* `language_code`. Full reference of languages https://cloud.google.com/speech-to-text/docs/languages\n",
    "* `model` (short commands, phone_call, video, etc)\n",
    "\n",
    "Some parameters are from the _beta_ version of the service, we can consider them more advanced: https://cloud.google.com/speech-to-text/docs/reference/rest/v1p1beta1/RecognitionConfig\n",
    "\n",
    "* `enable_automatic_punctuation`: adds punctuation to recognition result hypotheses\n",
    "* `enable_speaker_diarization` recognizes different speakers\n",
    "* `diarization_speaker_count` how many speakers in the interview\n",
    "\n",
    "Finally, the full Python docs (for the library) are here: https://google-cloud-python.readthedocs.io/en/0.32.0/index.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "    #sample_rate_hertz=16000,\n",
    "    language_code='en-US',\n",
    "\n",
    "    model='default',\n",
    "\n",
    "    enable_automatic_punctuation=True,\n",
    "    \n",
    "    enable_word_time_offsets=False, # this simplifies the output.\n",
    "                                    # Remove if you want more detail\n",
    "\n",
    "    # enable_speaker_diarization=True,  # good for interviews\n",
    "    # diarization_speaker_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a `RecognitionAudio` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = types.RecognitionAudio(uri=audio_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we start the _long running_ transcription process. Google will download the audio file from Cloud Storage, and transcribe it directly from there. This operation will return immediatelly, **but the processing is transfered to Google's servers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = client.long_running_recognize(config, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to get the results from the long running operation. Depending how long your audio was, this might take more time. For our demo audio (~30 secs), it'll be done pretty much immediately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation.done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = operation.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it worked correctly, it'll divide the transcription in multiple chunks, that are accessed as `results`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a preview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each result has multiple \"alternatives\", based on the configuration that we defined at the beginning. As I kept my configuration simple, I only have 1 alternative, which also lists the confidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.results[0].alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.results[0].alternatives[0].confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the transcribed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.results[0].alternatives[0].transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine all the results to generate the full text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = \"\\n\".join([result.alternatives[0].transcript for result in response.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textwrap.fill(full_text, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it again to our original audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"jacob-keynote.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning our transcription\n",
    "\n",
    "If you listen carefully, Jacob says he's \"Director of Security at the **_Heroku_**\". But the transcription picks _\"Roku\"_. We can improve this by passing the service a list of important terms we know are either proper nouns, or names, or special terms that won't be so easily interpreted. To do that we'll pass _speech context_, here are the docs: https://cloud.google.com/speech-to-text/docs/basics#phrase-hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another configuration object, this time check at the `speach_contexts` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "    #sample_rate_hertz=16000,\n",
    "    language_code='en-US',\n",
    "\n",
    "    model='default',\n",
    "\n",
    "    enable_automatic_punctuation=True,\n",
    "    \n",
    "    enable_word_time_offsets=False, # this simplifies the output.\n",
    "                                    # Remove if you want more detail\n",
    "\n",
    "    speech_contexts=[speech.types.SpeechContext(\n",
    "        phrases=['Heroku',],  # Only one term\n",
    "    )],\n",
    "    # enable_speaker_diarization=True,  # good for interviews\n",
    "    # diarization_speaker_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll restart the process now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = client.long_running_recognize(config, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = operation.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = \"\\n\".join([result.alternatives[0].transcript for result in response.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textwrap.fill(full_text, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's amazing! It now says _\"director of security at Heroku\"_. You can do this if you have a list of terms that your transcriptions have to pick up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, writing the results to a file\n",
    "\n",
    "We can now write the results to a file. **Warning!** Python will erase the contents of `result.txt` if it already exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as fp:\n",
    "    fp.write(textwrap.fill(full_text, 80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
